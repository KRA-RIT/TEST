{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Time_Date FinalShipQty TotalScrapQty R ShipQty InProcess Yield  \\\n",
      "0  20211027         3157           576         0            0.00   \n",
      "\n",
      "  Machine Yield Drill Down By  \n",
      "0         81.94     DefectGrp  \n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import timedelta, datetime, date\n",
    "import csv\n",
    "import pandas\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "\n",
    "#out_path = r'O:\\PDI-Barlap\\Aoo\\YLD_MNT\\EAGLERAYBP.csv'\n",
    "out_path = r'O:\\PDI-Barlap\\Aoo\\YLD_MNT\\FDBHMR6ET.csv'\n",
    "#product = 'EAGLERAYBP'\n",
    "product = 'FDBHMR6ET'\n",
    "FY_Car = r'O:\\PDI-Barlap\\Aoo\\YLD_MNT\\Calendar.csv'\n",
    "start_date = date(2021, 10, 27)\n",
    "end_date = date(2021, 10, 28)\n",
    "delta = end_date - start_date\n",
    "delta = delta.days\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "for single_date in daterange(start_date, end_date):\n",
    "    date = single_date.strftime(\"%Y%m%d\")\n",
    "    url = \"http://tkfis2.kor.thai.seagate.com:8080/yts/newOP_Binning/op_trend.asp?Type=Time_Date&Trend=True&DSL=&StartDate=\"+date+\"&EndDate=\"+date+\"&RType=MC&BType=&Wxyz=ALL&Shift=ALL&Family=&Product=\"+product+\"&Wafer=&WaferType=&AutoZMVOU=&ReInstate=&Cell=&PILot=&Omit=&Owner=PROD,%20FDB,%20NPD,%20PCTU&Category=&Ratio=&Bin=&EVALFLG=&EVALOPT=EVAL&Eval=&STEPOPT=GStep\"\n",
    "    html_content = requests.get(url).text\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    fil = soup.find(\"table\", {\"cellspacing\": \"2\"})\n",
    "    body = fil.find_all(\"tr\")\n",
    "    ls = []\n",
    "    #trend = []\n",
    "    for row in body:\n",
    "        elements = row.find_all('td')\n",
    "    \n",
    "        ls_elements_in_row = []\n",
    "        \n",
    "        for element in elements:\n",
    "            text = element.text\n",
    "            ls_elements_in_row += [text]\n",
    "            \n",
    "        ls += [ls_elements_in_row]\n",
    "    df = pd.DataFrame(ls[1:2:])\n",
    "    df.columns = ls[0]\n",
    "    #dy = df\n",
    "    trend = pd.concat([dy,df])\n",
    "    dy = trend\n",
    "print(trend)\n",
    "print(\"*************************************************************************************\")\n",
    "dy = dy.iloc[0:0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DEF_CODE            DESCRIPTION REASONQTY BONUSQTY NORMALISED Time_Date\n",
      "0       000        BONUS / UNSCRAP         0        0          0  20211027\n",
      "1       010                    AMP       407        0      70.66  20211027\n",
      "2       020             BREAKPOINT         0        0          0  20211027\n",
      "3       030          WAFER DEFECTS        45        0       7.81  20211027\n",
      "4       040                 CONTAM         9        0       1.56  20211027\n",
      "5       050                    DLC         0        0          0  20211027\n",
      "6       060                MILLING        27        0       4.69  20211027\n",
      "7       070                  PHOTO         0        0          0  20211027\n",
      "8       080      SUB CHIPS / CRACK         0        0          0  20211027\n",
      "9       090  ALUMINA CHIPS / CRACK         0        0          0  20211027\n",
      "10      100                  METAL         6        0       1.04  20211027\n",
      "11      110          STRIPE HEIGHT         0        0          0  20211027\n",
      "12      120            MACHINE ERR         0        0          0  20211027\n",
      "13      130             BROKEN BAR         0        0          0  20211027\n",
      "14      140     POLE TIP RECESSION         0        0          0  20211027\n",
      "15      150                   POLE         8        0       1.39  20211027\n",
      "16      160                MISSING         0        0          0  20211027\n",
      "17      170                   MISC        54       54          0  20211027\n",
      "18      180            HUMAN ERROR         0        0          0  20211027\n",
      "19      190       MOUNT / ASSEMBLY         0        0          0  20211027\n",
      "20      200               FLATNESS         0        0          0  20211027\n",
      "21      210                  SLICE         0        0          0  20211027\n",
      "22      220                   SSEC         0        0          0  20211027\n",
      "23      230        STRIP DIMENSION         0        0          0  20211027\n",
      "24      240               SAMPLING        20        0       3.47  20211027\n",
      "25      250            PARA DEFECT         0        0          0  20211027\n",
      "26      260               MILL RUN         0        0          0  20211027\n",
      "27      270            CARRIER RUN         0        0          0  20211027\n",
      "28      280               WIREBOND         0        0          0  20211027\n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for single_date in daterange(start_date, end_date):\n",
    "    date1 = single_date.strftime(\"%Y%m%d\")\n",
    "    ttsc1 = trend.loc[trend.Time_Date == date1,'TotalScrapQty'].values[0]\n",
    "    url1 = \"http://tkfis2.kor.thai.seagate.com:8080/yts/newOP_Binning/op_defectgrp.asp?Trend=True&DSL=&StartDate=\"+date1+\"&EndDate=\"+date1+\"&RType=MC&BType=&Wxyz=ALL&Shift=ALL&Family=&Product=\"+product+\"&Wafer=&WaferType=&Cell=&PILot=&Omit=&Owner=PROD,%20FDB,%20NPD,%20PCTU&RShipQty=0&TotalScrap=\"+ttsc1+\"&CummYield=0&Bin=&EVALFLG=&EVALOPT=EVAL&Eval=\"\n",
    "    html_content1 = requests.get(url1).text\n",
    "    soup1 = BeautifulSoup(html_content1, \"html.parser\")\n",
    "    fil1 = soup1.find(\"table\", {\"cellspacing\": \"2\"})\n",
    "    body1 = fil1.find_all(\"tr\")\n",
    "    ls1 = []\n",
    "    defectgroup = []\n",
    "    for row1 in body1:\n",
    "        elements1 = row1.find_all('td')\n",
    "    \n",
    "        ls_elements_in_row1 = []\n",
    "        \n",
    "        for element1 in elements1:\n",
    "            text1 = element1.text\n",
    "            ls_elements_in_row1 += [text1]\n",
    "            \n",
    "        ls1 += [ls_elements_in_row1]\n",
    "    df1 = pd.DataFrame(ls1[1:30:])\n",
    "    df1.columns = ls1[0]\n",
    "    df1['Time_Date'] = date1\n",
    "    #dy1 = df1\n",
    "    defectgroup = pd.concat([dy1,df1])\n",
    "    dy1 = defectgroup\n",
    "defectgroup.drop(columns=[\"Drill Down By\"], axis=1, inplace=True)\n",
    "print(defectgroup)\n",
    "print(\"*************************************************************************************\")\n",
    "dy1 = dy1.iloc[0:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DEF_CODE STEPNAME REASONCODE STARTQTY REASONQTY BONUSQTY DEFECTPERCENTAGE  \\\n",
      "0                                                                             \n",
      "\n",
      "  NORMALISED Time_Date  \n",
      "0                       \n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for single_date in daterange(start_date, end_date):\n",
    "    date2 = single_date.strftime(\"%Y%m%d\")\n",
    "    ttsc2 = trend.loc[trend.Time_Date == date2,'TotalScrapQty'].values[0]\n",
    "    defect21 = \"110\"\n",
    "    rsq21 = defectgroup.loc[(defectgroup.DEF_CODE == defect21) & (defectgroup.Time_Date == date2) ,'REASONQTY'].values[0]\n",
    "    url2 = \"http://tkfis2.kor.thai.seagate.com:8080/yts/newOP_Binning/op_defect.asp?DrillDownBy=Defect&DSL=&StartDate=\"+date2+\"&EndDate=\"+date2+\"&RType=MC&BType=&Wxyz=ALL&Shift=ALL&Family=&Product=\"+product+\"&Wafer=&WaferType=&AutoZMVOU=&ReInstate=&Cell=&PILot=&Omit=&Owner=PROD,%20FDB,%20NPD,%20PCTU&SBRNumber=&EVALFLG=&EVALOPT=EVAL&Eval=&STEPOPT=&Category=&DefectCode=\"+defect21+\"&Trend=Another&TotalScrap=\"+ttsc2+\"&CummYield=0\"\n",
    "    html_content2 = requests.get(url2).text\n",
    "    soup2 = BeautifulSoup(html_content2, \"html.parser\")\n",
    "    fil2 = soup2.find(\"table\", {\"cellspacing\": \"2\"})\n",
    "    body2 = fil2.find_all(\"tr\")\n",
    "    body_rows2 = body2[:2]\n",
    "    ls2 = []\n",
    "    drilldown_110 = []\n",
    "    if rsq21 != \"0\":\n",
    "        for row2 in body2:\n",
    "\n",
    "            elements2 = row2.find_all('td')\n",
    "    \n",
    "            ls_elements_in_row2 = []\n",
    "        \n",
    "            for element2 in elements2:\n",
    "                text2 = element2.text\n",
    "                ls_elements_in_row2 += [text2]\n",
    "            ls2 += [ls_elements_in_row2]     \n",
    "        df2 = pd.DataFrame(ls2[1::])\n",
    "        df2.columns = ls2[0]\n",
    "        df2 = df2.iloc[:-1,:]\n",
    "        df2['Time_Date'] = date2\n",
    "        #dy2 = df2\n",
    "        drilldown_110 = pd.concat([dy2,df2])\n",
    "        dy2 = drilldown_110\n",
    "    else:\n",
    "        idx = [\"DEF_CODE\", \"STEPNAME\", \"REASONCODE\", \"STARTQTY\", \"REASONQTY\", \"BONUSQTY\", \"DEFECTPERCENTAGE\", \"NORMALISED\", \"Drill Down By\", \"Time_Date\"]\n",
    "        drilldown_110 = pd.DataFrame(np.array([[\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"]]), columns=idx)\n",
    "drilldown_110.drop(columns=[\"Drill Down By\"], axis=1, inplace=True)\n",
    "print(drilldown_110)\n",
    "print(\"*************************************************************************************\")\n",
    "dy2 = dy2.iloc[0:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DEF_CODE STEPNAME REASONCODE STARTQTY REASONQTY BONUSQTY DEFECTPERCENTAGE  \\\n",
      "0                                                                             \n",
      "\n",
      "  NORMALISED Time_Date  \n",
      "0                       \n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for single_date in daterange(start_date, end_date):\n",
    "    date2 = single_date.strftime(\"%Y%m%d\")\n",
    "    ttsc2 = trend.loc[trend.Time_Date == date2,'TotalScrapQty'].values[0]\n",
    "    defect21 = \"130\"\n",
    "    rsq21 = defectgroup.loc[(defectgroup.DEF_CODE == defect21) & (defectgroup.Time_Date == date2) ,'REASONQTY'].values[0]\n",
    "    url2 = \"http://tkfis2.kor.thai.seagate.com:8080/yts/newOP_Binning/op_defect.asp?DrillDownBy=Defect&DSL=&StartDate=\"+date2+\"&EndDate=\"+date2+\"&RType=MC&BType=&Wxyz=ALL&Shift=ALL&Family=&Product=\"+product+\"&Wafer=&WaferType=&AutoZMVOU=&ReInstate=&Cell=&PILot=&Omit=&Owner=PROD,%20FDB,%20NPD,%20PCTU&SBRNumber=&EVALFLG=&EVALOPT=EVAL&Eval=&STEPOPT=&Category=&DefectCode=\"+defect21+\"&Trend=Another&TotalScrap=\"+ttsc2+\"&CummYield=0\"\n",
    "    html_content2 = requests.get(url2).text\n",
    "    soup2 = BeautifulSoup(html_content2, \"html.parser\")\n",
    "    fil2 = soup2.find(\"table\", {\"cellspacing\": \"2\"})\n",
    "    body2 = fil2.find_all(\"tr\")\n",
    "    body_rows2 = body2[:2]\n",
    "    \n",
    "    ls2 = []\n",
    "    data_list2 = []\n",
    "    drilldown_130 = []\n",
    "    body3 = body2[:2]\n",
    "    if rsq21 != \"0\":\n",
    "        for row2 in body2:\n",
    "            elements2 = row2.find_all('td')\n",
    "            \n",
    "            ls_elements_in_row2 = []\n",
    "        \n",
    "            for element2 in elements2:\n",
    "                text2 = element2.text\n",
    "                ls_elements_in_row2 += [text2]\n",
    "            ls2 += [ls_elements_in_row2]     \n",
    "        df2 = pd.DataFrame(ls2[1::])\n",
    "        df2.columns = ls2[0]\n",
    "        df2 = df2.iloc[:-1,:]\n",
    "        df2['Time_Date'] = date2\n",
    "        #dy2 = df2\n",
    "        drilldown_130 = pd.concat([dy2,df2])\n",
    "        dy2 = drilldown_130\n",
    "    else:\n",
    "        idx = [\"DEF_CODE\", \"STEPNAME\", \"REASONCODE\", \"STARTQTY\", \"REASONQTY\", \"BONUSQTY\", \"DEFECTPERCENTAGE\", \"NORMALISED\", \"Drill Down By\", \"Time_Date\"]\n",
    "        drilldown_130 = pd.DataFrame(np.array([[\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"]]), columns=idx)\n",
    "drilldown_130.drop(columns=[\"Drill Down By\"], axis=1, inplace=True)\n",
    "print(drilldown_130)\n",
    "print(\"*************************************************************************************\")\n",
    "dy2 = dy2.iloc[0:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DEF_CODE STEPNAME REASONCODE STARTQTY REASONQTY BONUSQTY DEFECTPERCENTAGE  \\\n",
      "0                                                                             \n",
      "0                                                                             \n",
      "\n",
      "  NORMALISED Time_Date  \n",
      "0                       \n",
      "0                       \n",
      "*************************************************************************************\n",
      "Empty DataFrame\n",
      "Columns: [DEF_CODE, STEPNAME, REASONCODE, STARTQTY, REASONQTY, BONUSQTY, DEFECTPERCENTAGE, NORMALISED, Time_Date]\n",
      "Index: []\n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "drill = pd.concat([drilldown_110,drilldown_130])\n",
    "print(drill)\n",
    "print(\"*************************************************************************************\")\n",
    "drill = drill.iloc[0:0]\n",
    "print(drill)\n",
    "print(\"*************************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "fiscal = pd.read_csv(FY_Car)\n",
    "old_data = pd.read_csv(out_path)\n",
    "#raw_data = pd.merge(trend, drill, on='Time_Date', how=\"inner\")\n",
    "raw_data = trend.append(drill)\n",
    "raw_data[\"PRODUCT\"] = product\n",
    "raw_data[\"Time_Date\"] = pd.to_numeric(raw_data[\"Time_Date\"])\n",
    "raw_data = pd.merge(fiscal, raw_data, on=\"Time_Date\", how=\"inner\")\n",
    "update_data = pd.concat([old_data,raw_data])\n",
    "print(\"*************************************************************************************\")\n",
    "#old_data.tail(5)\n",
    "#raw_data\n",
    "update_data.tail(7)\n",
    "#print(update_data.tail(5))\n",
    "update_data.to_csv(out_path, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a542ca580817fc4dd55327026e074e2fa0cd470fc5dee9350c2d8b13822db8d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 32-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "metadata": {
   "interpreter": {
    "hash": "7a542ca580817fc4dd55327026e074e2fa0cd470fc5dee9350c2d8b13822db8d"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
